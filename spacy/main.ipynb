{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy import displacy\n",
    "from spacy.util import filter_spans\n",
    "import pickle\n",
    "import fitz\n",
    "import pathlib as pl\n",
    "import random\n",
    "import re\n",
    "from rich import print as prt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in utils.v2Tov3Converter(train_data):\n",
    "#     for j in i.ents:\n",
    "#         prt(j.text, \" \", j.label_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open('train_data/train_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class utils:\n",
    "    # convert tuples to list and return converted data\n",
    "    def prepareData(train_data):\n",
    "        data = []\n",
    "        for text, annot in train_data:\n",
    "            ent = []\n",
    "            for strt, end, lbl in annot['entities']:\n",
    "                ent.append([strt, end, lbl])\n",
    "            annot['entities'] = ent\n",
    "            data.append([text, annot])\n",
    "        return data\n",
    "\n",
    "    # visualise training data using displacy\n",
    "    def renderData(data, start=0, end=1, serve=False):\n",
    "        nlp = spacy.blank('en')\n",
    "        data0 = data[start:end]\n",
    "        for text, annotations in data0:\n",
    "            doc = nlp.make_doc(text)\n",
    "            ents = []\n",
    "            for start, end, label in annotations['entities']:\n",
    "                span = doc.char_span(start, end, label=label)\n",
    "                if(span!=None):\n",
    "                    ents.append(span)\n",
    "            doc.ents = ents\n",
    "        if serve:\n",
    "            displacy.serve(doc, style='ent')\n",
    "        else:\n",
    "            displacy.render(doc, style='ent')\n",
    "\n",
    "    def remove_whitespace_entities(doc):\n",
    "        doc.ents = [e for e in doc.ents if not e.text.isspace()]\n",
    "        return doc\n",
    "\n",
    "    # convert training dataset from v2 to v3 using docbin\n",
    "    # note use filter_span to to get rid of the span errors\n",
    "    def v2Tov3Converter(data, filename=\"train\"):\n",
    "        nlp = spacy.blank(\"en\")\n",
    "        # the DocBin will store the example documents\n",
    "        db = DocBin()\n",
    "        for text, annotations in data:\n",
    "            doc = nlp.make_doc(text)\n",
    "            ents = []\n",
    "            for start, end, label in annotations['entities']:\n",
    "                # span = doc.char_span(start, end, label=label, alignment_mode='contract')\n",
    "                span = doc.char_span(start, end, label=label)\n",
    "                if span == None:\n",
    "                    continue\n",
    "                if span.text.isspace()==True:\n",
    "                    continue\n",
    "                proceed = True\n",
    "                span_text = span.text\n",
    "                if span_text[0]==' ' or span_text[len(span_text)-1]==' ':\n",
    "                    continue\n",
    "                for char in span.text:\n",
    "                    if char.isalnum():\n",
    "                        continue\n",
    "                    else:\n",
    "                        proceed = False\n",
    "\n",
    "                if proceed:\n",
    "                    ents.append(span)\n",
    "\n",
    "            ents = filter_spans(ents)\n",
    "            # prt(ents)\n",
    "            doc.ents = ents\n",
    "            doc = utils.remove_whitespace_entities(doc)\n",
    "            db.add(doc)\n",
    "        filename=filename+\".spacy\"\n",
    "        db.to_disk(filename)\n",
    "        return list(db.get_docs(nlp.vocab))\n",
    "    \n",
    "    def trim_entity_spans(data: list) -> list:\n",
    "        # Removes leading and trailing white spaces from entity spans.\n",
    "\n",
    "        # Args:\n",
    "        # data (list): The data to be cleaned in spaCy JSON format.\n",
    "\n",
    "        # Returns:\n",
    "        # list: The cleaned data.\n",
    "        invalid_span_tokens = re.compile(r'\\s')\n",
    "        cleaned_data = []\n",
    "        for text, annotations in data:\n",
    "            entities = annotations['entities']\n",
    "            valid_entities = []\n",
    "            for start, end, label in entities:\n",
    "                valid_start = start\n",
    "                valid_end = end\n",
    "                # if there's preceding spaces, move the start position to nearest character\n",
    "                while valid_start < len(text) and invalid_span_tokens.match(\n",
    "                        text[valid_start]):\n",
    "                    valid_start += 1\n",
    "                while valid_end > 1 and invalid_span_tokens.match(\n",
    "                        text[valid_end - 1]):\n",
    "                    valid_end -= 1\n",
    "\n",
    "                valid_entities.append([valid_start, valid_end, label])\n",
    "            cleaned_data.append([text, {'entities': valid_entities}])\n",
    "        return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = utils.v2Tov3Converter(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: en\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# initialize config.cfg file\n",
    "!spacy init config --lang en --pipeline ner config.cfg --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using config.cfg file. and save the model in trained_model folder.\n",
    "!python -m spacy train config.cfg --output ./trained_model/ --paths.train ./train.spacy --paths.dev ./train.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading and tesing trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tools:\n",
    "\n",
    "    def loadModel(model_dir = './trained_model/model-last'):\n",
    "        return spacy.load(model_dir)\n",
    "\n",
    "    def loadPdfs(dir='./data for testing'):\n",
    "        path = pl.Path(dir)\n",
    "        return list(path.glob(\"*.pdf\"))\n",
    "\n",
    "    def extractTextFromPdf(path, pdf_number):\n",
    "        pdf = fitz.open(path[pdf_number])\n",
    "        text = ''\n",
    "        for page in pdf:\n",
    "            text += str(page.getText())\n",
    "        text = \" \".join(text.split('\\n'))\n",
    "        return text\n",
    "    \n",
    "    def render(text):\n",
    "        displacy.render(nlp(text), style='ent')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Michael Smith  BI / Big Data/ Azure  Manchester, UK- Email me on Indeed: indeed.com/r/falicent/140749dace5dc26f    10+ years of Experience in Designing, Development, Administration, Analysis,  Management  inthe  Business  Intelligence  Data  warehousing,  Client  Server  Technologies, Web-based Applications, cloud solutions and Databases.  Data warehouse: Data analysis, star/ snow flake schema data modeling and design  specific todata warehousing and business intelligence environment.  Database: Experience in database designing, scalability, back-up and recovery,  writing andoptimizing SQL code and Stored Procedures, creating functions, views,  triggers and indexes.   Cloud platform: Worked on \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
       "</mark>\n",
       " Azure cloud services like Document DB, SQL  Azure, StreamAnalytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure  data lake analytics(U-SQL).  Big Data: Worked Azure data lake store/analytics for big data processing and Azure  data factoryto schedule U-SQL jobs. Designed and developed end to end big data  solution for data insights.     Willing to relocate: Anywhere  WORK EXPERIENCESoftware Engineer  \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
       "</mark>\n",
       " - Manchester, UK.  December 2015 to Present  1. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
       "</mark>\n",
       " Rewards Live dashboards:  Description: - \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
       "</mark>\n",
       " rewards is loyalty program that rewards Users for  browsing and shopping online. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
       "</mark>\n",
       " Rewards members can earn points when  searching with Bing, browsing with \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
       "</mark>\n",
       " Edge and making purchases at the  Xbox Store, the Windows Store and the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
       "</mark>\n",
       " Store. Plus, user can pick up  bonus points for taking daily quizzes and tours on the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
       "</mark>\n",
       " rewards website.  Rewards live dashboards gives a live picture of usage world-wide and by markets  like US, Canada, Australia, new user registration count, top/bottom performing  rewards offers, orders stats and weekly trends of user activities, orders and new  user registrations. the PBI tiles gets refreshed in different frequencies starting  from 5 seconds to 30 minutes.  Technology/Tools used  Event hub, stream analytics and Power BI.  Responsibilities  Created stream analytics jobs to process event hub data  Created Power BI live dashboard to show live usage traffic, weekly trends, cards,  charts to showtop/bottom 10 offers and usage metrics.  2. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
       "</mark>\n",
       " Rewards Data Insights:  Description: - \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
       "</mark>\n",
       " rewards is loyalty program that rewards Users for  browsing and shopping online. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
       "</mark>\n",
       " Rewards members can earn points when  searching with Bing, browsing with \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
       "</mark>\n",
       " Edge and making purchases at the  Xbox Store, the Windows Store and the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
       "</mark>\n",
       " Store. Plus, user can pick up  bonus points for taking daily quizzes and tours on the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
       "</mark>\n",
       " rewards website.  Rewards data insights is data analytics and reporting platform, processes 20  million users daily activities and redemption across different markets like US,  Canada, Australia.  Technology/Tools used  Cosmos (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
       "</mark>\n",
       " big-data platform), c#, X-flow job monitoring, Power BI.  Responsibilities  Created big data scripts in cosmos  C# data extractors, processors and reducers for data transformation  Power BI dashboards  3. End to end tracking Tool:  Description: - This is real-time Tracking tool to track different business  transactions like order, order response, functional acknowledgement, invoice  flowing inside ICOE. It gives flexibility to customers to track their transactions  and appropriate error information in-case of any failure. Based on resource based  access control the tool gives flexibility to end user to perform different actions  like view transactions, search based on different filter criteria and view and  download actual message payload. End to end tracking tool stitches all the  business transaction like order to cash flow and connects different hops inside  ICOE like gateway, routing server, Processing server. It also connects different  systems like ICOE, partner end point and SAP.  Technology/Tools used  Azure Document db, Azure web job and Web APP, RBAC, Angular JS.  Responsibilities  Document dB stored procedures.  Web job to process event hub data and populate Document db• Web App API.  Stream analytics job to transform data  Power BI reports  4. Biztrack Tracking Tool:  Description: - This is real-time Tracking tool to track different business  transactions like order, order response, functional acknowledgement, invoice  flowing inside ICOE. It gives flexibility to customers to track their transactions  and appropriate error information in-case of any failure. Based on resource based  access control the tool gives flexibility to end user to perform different actions  like view transactions, search based on different filter criteria and view and  download actual message payload.  Technology/Tools used  SQL server 2014, SSIS, .net API, Angular JS.  Responsibilities  ETL solution to transform business transactions data stored in Biztalk tables.  SQL azure tables, stored procedures, User defined functions.  Performance tuning.  Web API enhancements.    EDUCATION  The University of Manchester - UK  2007    SKILLS  problem solving (Less than 1 year), project lifecycle (Less than 1 year), project  manager (Less than 1 year), technical assistance. (Less than 1 year)  ADDITIONAL INFORMATION  Professional Skills  Excellent analytical, problem solving, communication, knowledge transfer and  interpersonalskills with ability to interact with individuals at all the levels  Quick learner and maintains cordial relationship with project manager and team  members andgood performer both in team and independent job environments  Positive attitude towards superiors &amp;amp; peers  Supervised junior developers throughout project lifecycle and provided technical  assistance.  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = tools.loadModel()\n",
    "pdfs = tools.loadPdfs()\n",
    "text = tools.extractTextFromPdf(pdfs, 1)\n",
    "tools.render(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
